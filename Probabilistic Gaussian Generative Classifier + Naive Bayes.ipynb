{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "938be637",
   "metadata": {},
   "source": [
    "# Part a: Gaussian Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67c2cbb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5961111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from numpy.linalg import slogdet, inv\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4a7b5",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58e90c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = sklearn.datasets.load_digits()\n",
    "## load the digits dataset from sklearn\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "## Create a 70% / 15% / 15% split:\n",
    "X_train, X_temp, y_train, y_temp = sklearn.model_selection.train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = sklearn.model_selection.train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "##  standardize the features\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_val=scaler.transform(X_val)\n",
    "X_test=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f8b8d",
   "metadata": {},
   "source": [
    "### 1. compute class priors pi_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class priors: [0.09864757 0.10103421 0.09864757 0.10182975 0.10103421 0.10103421\n",
      " 0.10103421 0.09944312 0.09705648 0.10023866]\n"
     ]
    }
   ],
   "source": [
    "#pi_k = P(y=k)\n",
    "K= 10\n",
    "N= X_train.shape[0] \n",
    "pi = np.zeros(K)\n",
    "for k in range(K):\n",
    "    pi[k] = np.sum(y_train == k) / N\n",
    "\n",
    "print(\"Class priors:\", pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a734d4",
   "metadata": {},
   "source": [
    "### 2. compute class means mu_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29747f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class means shape: (10, 64)\n"
     ]
    }
   ],
   "source": [
    "# mu_k = E[x|y=k]\n",
    "D= X_train.shape[1]\n",
    "mu = np.zeros((K,D))\n",
    "for k in range(K):\n",
    "    mu[k] = np.mean(X_train[y_train == k], axis=0) # x given y=k \n",
    "\n",
    "print(\"Class means shape:\", mu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919360a",
   "metadata": {},
   "source": [
    "### 3. compute shared covariance Σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb44b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared covariance shape: (64, 64)  trace: 41.085022049776384\n"
     ]
    }
   ],
   "source": [
    "# sigma= 1/n * sum_i (x_i - mu_(y_i))(x_i - mu_(y_i))^T\n",
    "sigma = np.zeros((D,D))\n",
    "for i in range(N):\n",
    "    diff= (X_train[i] - mu[y_train[i]])[:,None] # make it a column vector (D x 1)\n",
    "    sigma += diff.dot(diff.T)\n",
    "sigma /= N\n",
    "print(\"Shared covariance shape:\", sigma.shape, \" trace:\", np.trace(sigma)) #trace is sum of diagonal elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b89ab",
   "metadata": {},
   "source": [
    "### 4. regularise Σ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764ecebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized covariance shape: (64, 64)  trace: 41.14902204977638\n"
     ]
    }
   ],
   "source": [
    "# Σ_λ= Σ + λI\n",
    "lambda_reg = 1e-3\n",
    "sigma_reg = sigma + lambda_reg * np.eye(D)\n",
    "print(\"Regularized covariance shape:\", sigma_reg.shape, \" trace:\", np.trace(sigma_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5867ea",
   "metadata": {},
   "source": [
    "### 5. computing log Gaussian scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b93987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume p(x|y=k) ~ N(x;mu_k, Σ_λ) and p(y=k) = pi_k\n",
    "# What we calculate is posterior score of sample x for class k = log p(y=k) + log p(x|y=k) <------- important\n",
    "# log p(x|y=k) = -0.5 * [ D log(2pi) + log|Σ_λ| + (x - mu_k)^T Σ_λ^-1 (x - mu_k) ] from the multivariate normal distribution\n",
    "# the term -0.5 * D log(2pi)- 0.5 * log|Σ_λ| is constant for all classes, so we can ignore it in the score computation\n",
    "\n",
    "def compute_scores(X):\n",
    "    N= X.shape[0]\n",
    "    D= X.shape[1]\n",
    "    K= mu.shape[0]\n",
    "    scores= np.zeros((N,K))\n",
    "    sign, logdet= slogdet(sigma_reg)\n",
    "    if sign <= 0:\n",
    "        raise ValueError(\"Covariance matrix is not positive definite.\")\n",
    "    sigma_inv= inv(sigma_reg)\n",
    "    const_term= -0.5 * (D * np.log(2*np.pi) + logdet) # constant term for all classes\n",
    "    for k in range(K):\n",
    "        diff= X - mu[k] \n",
    "        for i in range(N):\n",
    "            mahalanobis= diff[i].T.dot(sigma_inv).dot(diff[i])\n",
    "            log_likelihood= const_term - 0.5 * mahalanobis\n",
    "            scores[i,k]= np.log(pi[k]) + log_likelihood\n",
    "    return scores\n",
    "\n",
    "# for each sample in X, compute scores and predict the class with highest score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02652010",
   "metadata": {},
   "source": [
    "### Functions to predict and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0bfe8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_scores(scores):\n",
    "    return np.argmax(scores, axis=1)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0105be",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c31bf355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Lambda  Validation Accuracy\n",
      "0   0.0001             0.944444\n",
      "1   0.0010             0.944444\n",
      "2   0.0100             0.944444\n",
      "3   0.1000             0.944444\n",
      "4   1.0000             0.922222\n",
      "5  10.0000             0.848148\n",
      "\n",
      "best lambda: 0.0001 val acc: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "lambdas= [1e-4, 1e-3, 1e-2, 1e-1, 1, 10]\n",
    "best_acc = -np.inf\n",
    "best_lam = None\n",
    "lambdas_table= []\n",
    "\n",
    "for lambda_reg in lambdas:\n",
    "    sigma_reg = sigma + lambda_reg * np.eye(D)\n",
    "    scores_val= compute_scores(X_val)\n",
    "    y_val_pred= predict_from_scores(scores_val)\n",
    "    acc= accuracy(y_val, y_val_pred)\n",
    "    if acc> best_acc:\n",
    "        best_acc=acc\n",
    "        best_lam=lambda_reg\n",
    "    lambdas_table.append((lambda_reg, acc))\n",
    "    \n",
    "lambdas_df= pd.DataFrame(lambdas_table, columns=['Lambda', 'Validation Accuracy'])\n",
    "print(lambdas_df)\n",
    "print(\"\\nbest lambda:\", best_lam, \"val acc:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2ebaba",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7e215f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final accuracy on combined train+val set with lambda=0.0001: 96.46%\n"
     ]
    }
   ],
   "source": [
    "# combine train and val sets for final evaluation\n",
    "X_combined= np.vstack((X_train, X_val))\n",
    "y_combined= np.hstack((y_train, y_val))\n",
    "N_combined= X_combined.shape[0]\n",
    "lambda_reg = best_lam\n",
    "sigma_reg = sigma + lambda_reg * np.eye(D)\n",
    "scores_final= compute_scores(X_combined)\n",
    "y_final_pred= predict_from_scores(scores_final)\n",
    "final_acc= accuracy(y_combined, y_final_pred)\n",
    "print(f\"\\nFinal accuracy on combined train+val set with lambda={best_lam}: {final_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef98e93",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe351da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy evaluation:  96.46%\n",
      "Macro averaged precision:  96.52%\n",
      "Macro averaged recall:  96.46%\n",
      "Macro averaged F1-score:  96.48%\n",
      "Confusion Matrix:\n",
      " [[150   0   0   0   0   0   1   0   0   0]\n",
      " [  0 146   1   0   1   0   0   0   2   4]\n",
      " [  0   0 148   3   0   0   0   0   0   0]\n",
      " [  0   0   1 149   0   1   0   0   3   1]\n",
      " [  0   1   0   0 149   0   0   1   2   1]\n",
      " [  0   0   0   0   0 147   1   0   0   7]\n",
      " [  0   2   0   0   1   0 151   0   0   0]\n",
      " [  0   0   0   0   0   0   0 150   0   2]\n",
      " [  0   6   0   0   0   0   0   1 139   2]\n",
      " [  0   0   0   1   0   1   0   2   5 144]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy evaluation: \",f\"{final_acc*100:.2f}%\")\n",
    "print(\"Macro averaged precision: \",f\"{precision_score(y_combined, y_final_pred, average='macro')*100:.2f}%\")\n",
    "print(\"Macro averaged recall: \",f\"{recall_score(y_combined, y_final_pred, average='macro')*100:.2f}%\")\n",
    "print(\"Macro averaged F1-score: \",f\"{f1_score(y_combined, y_final_pred, average='macro')*100:.2f}%\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_combined, y_final_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eed9ef1",
   "metadata": {},
   "source": [
    "## Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dfc0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short explanation of the Gaussian Generative Model , parameter estimation and regularization.\n",
    "# Gaussian Generative Model:\n",
    "# - We assume each class y=k has a prior probability π_k = p(y=k), estimated from the fraction of training samples in that class.\n",
    "# - The class-conditional distribution p(x | y=k) is multivariate Gaussian: x | y=k ~ N(μ_k, Σ), \n",
    "#   where μ_k is the mean vector for class k and Σ is a shared covariance matrix across all classes.\n",
    "# Parameter estimation:\n",
    "# - π_k: proportion of training samples in class k.\n",
    "# - μ_k: average of all training samples belonging to class k.\n",
    "# - Σ: accumulated outer product of deviations (x_i - μ_{y_i})(x_i - μ_{y_i})^T over all samples, divided by total number of samples.\n",
    "# Regularization:\n",
    "# - To ensure numerical stability and invertibility, we use Σ_λ = Σ + λI.\n",
    "# - λ > 0 prevents singular matrices and smooths the covariance; larger λ produces more “spherical” distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f114af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discussion:\n",
    "# The confusion matrix shows that certain digits are more frequently confused with each other, \n",
    "# particularly visually similar ones. For example, digits 1 and 7, or 3 and 8, are commonly misclassified, \n",
    "# while digits like 0, 4, and 6 are recognized very accurately. These confusions reflect the inherent similarity \n",
    "# in pixel patterns for these digits.\n",
    "\n",
    "# The choice of λ had a clear effect on performance. Small λ values can lead to overfitting, making the model \n",
    "# sensitive to noise in the training set, while very large λ oversmooths the covariance and reduces separation \n",
    "# between classes. Overall, the Gaussian generative model is fast, interpretable, and works well for distinct \n",
    "# digits, but its assumption of a shared covariance limits its ability to capture class-specific feature correlations, \n",
    "# and it struggles with overlapping or non-Gaussian patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b925e1",
   "metadata": {},
   "source": [
    "# Part b: Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294797e",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11101196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41416d95",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d31a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - LOADING THE DATA SET\n",
    "\n",
    "path = \"C:\\\\Users\\\\ghane\\\\Downloads\\\\adult.csv\\\\adult.csv\"\n",
    "df = pd.read_csv(path, skipinitialspace=True)\n",
    "\n",
    "\n",
    "# 2 - SELECTING THE FEATURES\n",
    "\n",
    "categorical_features = [\n",
    "    \"workclass\", \"education\", \"marital.status\", \"occupation\",\n",
    "    \"relationship\", \"race\", \"sex\", \"native.country\"\n",
    "]\n",
    "target_column = \"income\"\n",
    "\n",
    "# check if all columns are present\n",
    "for c in categorical_features + [target_column]:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Column missing: {c}\")\n",
    "\n",
    "df_categorial = df[categorical_features + [target_column]].copy()\n",
    "\n",
    "\n",
    "# 3 - CLEANING MISSING VALUES\n",
    "\n",
    "for f in categorical_features:\n",
    "    df_categorial[f] = df_categorial[f].fillna(\"Unkown\").astype(str).str.strip()\n",
    "    df_categorial[f] = df_categorial[f].replace(\"?\", \"Unkown\")\n",
    "\n",
    "\n",
    "# 4 - ENCODING FEATURES\n",
    "\n",
    "dictionary = {}\n",
    "X = pd.DataFrame()\n",
    "for f in categorical_features:\n",
    "    s = pd.Categorical(df_categorial[f])\n",
    "    mapping = {category: i for i, category in enumerate(s.categories)}\n",
    "    dictionary[f] = mapping\n",
    "    X[f] = s.codes.astype(int)\n",
    "\n",
    "Y = df_categorial[target_column].map({\"<=50K\": 0, \">50K\": 1})\n",
    "\n",
    "\n",
    "# 5 - TRAIN/VALIDATION/TEST SPLIT\n",
    "\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.15, stratify=Y, random_state=42\n",
    ")\n",
    "val_ratio = 0.15 / 0.85\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_temp, Y_temp, test_size=val_ratio, stratify=Y_temp, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9586eb4",
   "metadata": {},
   "source": [
    "## 1. Naive bayes class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac07194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesCategorical:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "        self.class_priors = {}\n",
    "        self.likelihoods = {}\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.classes = np.unique(Y)\n",
    "        n_samples, n_features = X.shape\n",
    "        class_count = Y.value_counts()\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        # calculate class priors with Laplace smoothing\n",
    "        self.class_priors = {\n",
    "            c: (class_count.get(c, 0) + self.alpha) / (n_samples + self.alpha * n_classes)\n",
    "            for c in self.classes\n",
    "        }\n",
    "\n",
    "        # calculate likelihoods for each feature given each class\n",
    "        for f in X.columns:\n",
    "            self.likelihoods[f] = {}\n",
    "            for c in self.classes:\n",
    "                X_c = X[Y == c]\n",
    "                value_counts = X_c[f].value_counts().to_dict()\n",
    "                n_values = len(X[f].unique())\n",
    "                self.likelihoods[f][c] = {\n",
    "                    k: (value_counts.get(k, 0) + self.alpha) / (len(X_c) + self.alpha * n_values)\n",
    "                    for k in X[f].unique()\n",
    "                }\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        proba = []\n",
    "        for _, row in X.iterrows():\n",
    "            class_probs = {}\n",
    "            for c in self.classes:\n",
    "                prob = self.class_priors[c]\n",
    "                for f in X.columns:\n",
    "                    prob *= self.likelihoods[f][c].get(\n",
    "                        row[f],\n",
    "                        self.alpha / (self.alpha * len(self.likelihoods[f][c]) + 1)\n",
    "                    )\n",
    "                class_probs[c] = prob\n",
    "            # normalize\n",
    "            total = sum(class_probs.values())\n",
    "            for k in class_probs:\n",
    "                class_probs[k] /= total\n",
    "            proba.append(class_probs)\n",
    "        return proba\n",
    "\n",
    "    def predict(self, X):\n",
    "        proba = self.predict_proba(X)\n",
    "        predictions = [max(p, key=p.get) for p in proba]\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd330449",
   "metadata": {},
   "source": [
    "## 2. Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d429cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7925880425880426\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayesCategorical(alpha=1.0)\n",
    "nb.fit(X_train, Y_train)\n",
    "y_val_pred = nb.predict(X_val)\n",
    "accuracy = (y_val_pred == Y_val.values).mean()\n",
    "print(\"Validation Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fb20ad",
   "metadata": {},
   "source": [
    "## 3. Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0221aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Smoothing Parameter (alpha) Test ---\n",
      "Alpha=0.1 -> Validation Accuracy: 0.7932\n",
      "Alpha=0.5 -> Validation Accuracy: 0.7932\n",
      "Alpha=1.0 -> Validation Accuracy: 0.7926\n",
      "Alpha=2.0 -> Validation Accuracy: 0.7922\n",
      "Alpha=5.0 -> Validation Accuracy: 0.7922\n",
      "\n",
      "--- Feature Selection Analysis ---\n",
      "Features=['education', 'occupation'] -> Validation Accuracy: 0.7809\n",
      "Features=['workclass', 'education', 'marital.status'] -> Validation Accuracy: 0.8227\n",
      "Features=['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country'] -> Validation Accuracy: 0.7926\n",
      "\n",
      "--- Probability Distribution Example ---\n",
      "Example predicted probabilities for first 5 samples:\n",
      "[[0.15670816 0.84329184]\n",
      " [0.15982106 0.84017894]\n",
      " [0.4920622  0.5079378 ]\n",
      " [0.9793634  0.0206366 ]\n",
      " [0.99555899 0.00444101]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Independence Assumption ---\n",
      "Naive Bayes assumes features are independent given the class. In reality, features like education and occupation are correlated, which may make probabilities slightly biased.\n"
     ]
    }
   ],
   "source": [
    "# 1 - Smoothing Parameter Test\n",
    "print(\"\\n--- Smoothing Parameter (alpha) Test ---\")\n",
    "alpha_values = [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "for a in alpha_values:\n",
    "    nb_a = NaiveBayesCategorical(alpha=a)\n",
    "    nb_a.fit(X_train, Y_train)\n",
    "    y_val_pred = nb_a.predict(X_val)\n",
    "    acc = (y_val_pred == Y_val.values).mean()\n",
    "    print(f\"Alpha={a} -> Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 2 - Feature Selection\n",
    "print(\"\\n--- Feature Selection Analysis ---\")\n",
    "feature_subsets = [\n",
    "    [\"education\", \"occupation\"],\n",
    "    [\"workclass\", \"education\", \"marital.status\"],\n",
    "    categorical_features\n",
    "]\n",
    "for subset in feature_subsets:\n",
    "    nb_feat = NaiveBayesCategorical(alpha=1.0)\n",
    "    nb_feat.fit(X_train[subset], Y_train)\n",
    "    y_val_pred = nb_feat.predict(X_val[subset])\n",
    "    acc = (y_val_pred == Y_val.values).mean()\n",
    "    print(f\"Features={subset} -> Validation Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 3 - Probability Analysis\n",
    "print(\"\\n--- Probability Distribution Example ---\")\n",
    "proba_val = nb.predict_proba(X_val)\n",
    "proba_array = np.array([[p[0], p[1]] for p in proba_val])\n",
    "print(\"Example predicted probabilities for first 5 samples:\")\n",
    "print(proba_array[:5])\n",
    "plt.hist(proba_array[:, 1], bins=20)\n",
    "plt.xlabel(\"Predicted probability for >50K\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Probability Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# 4 - Independence Assumption\n",
    "print(\"\\n--- Independence Assumption ---\")\n",
    "print(\"Naive Bayes assumes features are independent given the class. In reality, features like education and occupation are correlated, which may make probabilities slightly biased.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0ca090",
   "metadata": {},
   "source": [
    "## 4. Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "750be63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Sklearn MultinomialNB Comparison ---\n",
      "Sklearn MultinomialNB Validation Accuracy: 0.7516380016380017\n"
     ]
    }
   ],
   "source": [
    "# 5 - Compare with sklearn's MultinomialNB\n",
    "print(\"\\n--- Sklearn MultinomialNB Comparison ---\")\n",
    "mnb = MultinomialNB(alpha=1.0)\n",
    "mnb.fit(X_train, Y_train)\n",
    "y_val_pred_skl = mnb.predict(X_val)\n",
    "acc_skl = (y_val_pred_skl == Y_val.values).mean()\n",
    "print(\"Sklearn MultinomialNB Validation Accuracy:\", acc_skl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305d7f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
